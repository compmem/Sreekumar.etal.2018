{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/nielsond/python/envs/py27mvpa/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# These are global imports\n",
    "%pylab inline\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import rankdata\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import ndimage\n",
    "import cPickle as pickle\n",
    "from joblib import Parallel,delayed\n",
    "# Connect to an R session\n",
    "import nibabel as nb\n",
    "\n",
    "\n",
    "from mvpa2.suite import *\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial.distance import squareform,pdist\n",
    "from scipy.stats import rankdata,pearsonr\n",
    "from scipy import stats\n",
    "\n",
    "#import prettyplotlib as ppl\n",
    "#import brewer2mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from nibabel.spatialimages import ImageFileError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ttest, make stat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_name = 'perm_ham_stlim_SL4_zndist_1000perms_v1'\n",
    "#define formula for glm, this is also a thing that may change run to run\n",
    "fe_formula = 'val~ham+event'  # MODEL 3\n",
    "\n",
    "#run_name='perm_ham_hamvivave_viv_ave_stlim_SL4_zndist_500perms'\n",
    "#'perm_ham_hamremaverecoded_stlim_SL_zndist'\n",
    "method = 'glm'\n",
    "run_type = '%s_sl'%(method)\n",
    "\n",
    "basedir = '/data/nielsond/expSamp/data/'\n",
    "data_dir = os.path.join(basedir,'input')\n",
    "data_file = 'rsa_dataset_gps_time_old_exclude_drop_viv_bin_scan_time_rem_ham.pickle'  \n",
    "outdir = '/data/nielsond/expSamp/data/output/%s_sl/%s'%(method,run_name)\n",
    "ss_out_pat = 'betas.%s.%s.%s.%03d.nii.gz'\n",
    "combined_out_pat = '%s.%s.%s.nii.gz'\n",
    "fmri_pat = 'input/stb.%s_stb_qwarp_e2a.nii.gz'\n",
    "subj_mask_pat = 'input/%s_mask_GM_full_+tlrc.nii.gz'\n",
    "stat_out_pat = '%s.%s.%s.%s.%03d.nii.gz'\n",
    "\n",
    "mask_path='/data/nielsond/expSamp/data/input/MNI152_T1_2.5mm_GM_mask.nii.gz'\n",
    "    \n",
    "\n",
    "subjects = ['expSamp01',\n",
    "'expSamp02',\n",
    "'expSamp03',\n",
    "'expSamp04',\n",
    "'expSamp05',\n",
    "'expSamp07',\n",
    "'expSamp08',\n",
    "'expSamp09',\n",
    "'expSamp10']\n",
    "\n",
    "\n",
    "#make output directory if it doesn't exist\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "#load independent data\n",
    "dat = np.load(os.path.join(data_dir,data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nielsond/expSamp/data/output/glm_sl/perm_ham_stlim_SL4_zndist_1000perms_v1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 4\n",
    "contrasts = {'event':1,'ham':2}\n",
    "model_meas = {'deviance':(6),\n",
    "             'scale':(7),\n",
    "             'llf':(8),\n",
    "             'count':(9)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 3\n",
    "contrasts = {'correl':1,'event':2,'ham':3}\n",
    "model_meas = {'deviance':(8),\n",
    "             'scale':(9),\n",
    "             'llf':(10),\n",
    "             'count':(11)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2\n",
    "contrasts = {'event':1,'ham':2,'ham-viv_ave':3,'viv_ave':4}\n",
    "model_meas = {'deviance':(10),\n",
    "             'scale':(11),\n",
    "             'llf':(12),\n",
    "             'count':(13)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrasts = {'correl':1,'event':2,'ham':3,'ham-viv_ave':4,\n",
    "             'space':5, 'space:time':6,'time':7,'viv_ave':8}\n",
    "model_meas = {'deviance':(18),\n",
    "             'scale':(19),\n",
    "             'llf':(20),\n",
    "             'count':(21)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrasts = {'correl':1,'event':2,'ham':3,'ham-viv_ave':4,'viv_ave':5}\n",
    "model_meas = {'deviance':(12),\n",
    "             'scale':(13),\n",
    "             'llf':(14),\n",
    "             'count':(15)}\n",
    "\n",
    "#1 event betas\n",
    "#2 ham betas\n",
    "#3 space betas\n",
    "#4 space:time betas\n",
    "#5 time betas\n",
    "#6 Intercept tvals\n",
    "#7 event tvals\n",
    "#8 ham tvals\n",
    "#9 space tvals\n",
    "#10 space:time tvals\n",
    "#11 time tvals\n",
    "#12 deviance\n",
    "#13 scale\n",
    "#14 llf\n",
    "#15 count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grab dat mask\n",
    "mask = nb.load(mask_path) \n",
    "#stdmask = nb.load(std_mask_path)\n",
    "ind = (mask.get_data()>0) #& (stdmask.get_data()>0))\n",
    "count_thresh = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make output stats directory if it doesn't exist\n",
    "stats_dir = os.path.join(outdir,'stats')\n",
    "if not os.path.exists(stats_dir):\n",
    "    os.makedirs(stats_dir)\n",
    "\n",
    "  \n",
    "def proc_perm(n):\n",
    "    #betas = np.array([nb.load(os.path.join(outdir,ss_out_pat%(subj,run_name,run_type,n))).get_data()[ind] for subj in subjects]) #,n to ss_out_pat\n",
    "    #betas = np.array([nb.load(os.path.join(outdir,ss_out_pat%(subj,run_name,run_type))).get_data()[ind] for subj in subjects]) #,n to ss_out_pat\n",
    "    try:\n",
    "        betas = np.array([nb.load(os.path.join(outdir,ss_out_pat%(subj,run_name,run_type,n))).get_data()[ind] for subj in subjects]) #,n to ss_out_pat\n",
    "    except ImageFileError:\n",
    "        return n\n",
    "    c1=0 #checking any one factor is fine. If one is zero, the others are zero as well.\n",
    "    zerosphere_ind=numpy.where(betas[:,:,c1] == 0)[1]  \n",
    "    betas[:,zerosphere_ind,:]=np.NAN\n",
    "    \n",
    "    if len(betas) != 9:\n",
    "        print \"Perm %d not completed for all subjects\"\n",
    "    else:\n",
    "        ttest_res = {}\n",
    "        for c in contrasts.keys():\n",
    "            if type(contrasts[c]) == int:\n",
    "                ttest_res[c] = np.array(stats.ttest_1samp(betas[:,:,contrasts[c]],0.0,axis=0))\n",
    "            else:\n",
    "                ttest_res[c]=np.array(stats.ttest_rel(betas[:,:,contrasts[c][0]],\n",
    "                                                 betas[:,:,contrasts[c][1]]))\n",
    "\n",
    "        tvals = {fac:ttest_res[fac][0] for fac in ttest_res.keys() }\n",
    "        \n",
    "        #Adding min t stat map for the conjunction of keys in conj_keys\n",
    "        #Work with min of abs t vals\n",
    "        #tvals_conj = {fac:tvals[fac] for fac in conj_keys}\n",
    "        #tval_mat = np.zeros((len(conj_keys),len(tvals_conj[conj_keys[0]])))\n",
    "        #for idx in xrange(len(conj_keys)):\n",
    "        #    tval_mat[idx]=tvals_conj.items()[idx][1]\n",
    "        #tvals['conjunction']=np.absolute(tval_mat).min(axis=0)\n",
    "        ##\n",
    "        \n",
    "        count = np.array(np.average(betas[:,:,model_meas['count']],axis=0))\n",
    "        tvals_cmask = {fac:np.zeros(tvals[fac].shape) for fac in tvals.keys()}\n",
    "\n",
    "        for fac in tvals.keys():\n",
    "            tvals_cmask[fac][((~np.isnan(tvals[fac]))&(count>=count_thresh))] = tvals[fac][((~np.isnan(tvals[fac]))&(count>=count_thresh))]\n",
    "\n",
    "        save_ind = np.nonzero(ind.flat>0)[0] #ind used here, which was the ind for mask\n",
    "        measures = {'tvals_cmask':tvals_cmask}\n",
    "        for m in measures.keys():\n",
    "            for fac in tvals.keys():#ttest_res.keys():\n",
    "                outfile = os.path.join(outdir,'stats',stat_out_pat%(fac,m,run_name,run_type,n)) #,n to the end\n",
    "                #outfile = os.path.join(outdir,'vishstats',stat_out_pat%(fac,m,run_name,run_type)) #,n to the end\n",
    "                dat_tosave = np.zeros(mask.get_data().shape) \n",
    "                dat_tosave.flat[save_ind] = measures[m][fac]\n",
    "                img_out = nb.Nifti1Image(dat_tosave, \n",
    "                                 affine=mask.get_affine(), \n",
    "                                 header=mask.get_header())\n",
    "                #print outfile\n",
    "                img_out.to_filename(outfile)\n",
    "                \n",
    "        outfile = os.path.join(outdir,'stats',stat_out_pat%('count',m,run_name,run_type,n)) #,n to the end for perms\n",
    "        #outfile = os.path.join(outdir,'vishstats',stat_out_pat%('count',m,run_name,run_type)) #,n to the end for perms\n",
    "        dat_tosave = np.zeros(mask.get_data().shape)\n",
    "        dat_tosave.flat[save_ind] = count\n",
    "        img_out = nb.Nifti1Image(dat_tosave, \n",
    "                         affine=mask.get_affine(), \n",
    "                         header=mask.get_header())\n",
    "        #print outfile\n",
    "        img_out.to_filename(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process permutations\n",
    "fails = []\n",
    "for n in np.arange(0,1000):\n",
    "    fails.append(proc_perm(n))\n",
    "fm = [f is not None for f in fails]\n",
    "np.array(fails)[fm]\n",
    "\n",
    "#Reprocesses failed permutation\n",
    "new_fails = []\n",
    "for n in [fails]:\n",
    "    new_fails.append(proc_perm(n))\n",
    "\n",
    "print(new_fails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "from subprocess import CalledProcessError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = \"tvals_cmask\"\n",
    "pp_out_pat = '%s.%s.%s.%s.%s.%03d.nii.gz'\n",
    "merge_in_pat = '%s.%s.%s.%s.%s.*.nii.gz'\n",
    "\n",
    "merge_out_pat = '%s.%s.%s.%s.%s.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fac in contrasts.keys():#ttest_res.keys():\n",
    "    for n in range(1000):\n",
    "        infile = os.path.join(outdir,'stats',stat_out_pat%(fac,m,run_name,run_type,n))\n",
    "        tfce_pos_file = os.path.join(outdir,'stats',pp_out_pat%(fac,m,run_name,run_type,'tfce_pos',n))\n",
    "        tfce_file = os.path.join(outdir,'stats',pp_out_pat%(fac,m,run_name,run_type,'tfce',n))\n",
    "        sp.check_output(' '.join([\"fslmaths\",infile,\"-thr 0\", \"-tfce 2 0.6666 26 \",tfce_pos_file]),shell = True)\n",
    "        try:\n",
    "            sp.check_output(' '.join([\"fslmaths\",infile,\"-mul -1 -thr 0 -tfce 2 0.6666 26 -mul -1 -add\",tfce_pos_file,tfce_file]),shell = True)\n",
    "        except CalledProcessError as e:\n",
    "            mint = float(sp.check_output(' '.join(['fslstats',infile,'-P 0']), shell = True).strip())\n",
    "            if mint >= 0:\n",
    "                sp.check_output(' '.join([\"fslmaths\",infile,\"-thr 0\", \"-tfce 2 0.6666 26 \",tfce_file]),shell = True)\n",
    "            else:\n",
    "                raise e\n",
    "        sp.check_output(' '.join(['rm',tfce_pos_file]), shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_thresh(f,q):\n",
    "    perm_res = []\n",
    "    with open(f,'r') as h:\n",
    "        perm_res = h.readlines()\n",
    "    perm_res = np.array([float(s.strip()) for s in perm_res])\n",
    "    return np.percentile(perm_res,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh_d = {}\n",
    "for fac in contrasts.keys():#ttest_res.keys(): \n",
    "    merge_input = os.path.join(outdir,'stats',merge_in_pat%(fac,m,run_name,run_type,'tfce'))\n",
    "    merge_file = os.path.join(outdir,'stats',merge_out_pat%(fac,m,run_name,run_type,'merge'))\n",
    "    max_file = os.path.join(outdir,'stats',merge_out_pat%(fac,m,run_name,run_type,'max_vals'))\n",
    "    min_file = os.path.join(outdir,'stats',merge_out_pat%(fac,m,run_name,run_type,'min_vals'))\n",
    "\n",
    "    sp.check_output(' '.join([\"fslmerge -t\",merge_file,merge_input]),shell = True)\n",
    "    sp.check_output(' '.join([\"fslstats -t\",merge_file,\"-P 100 >\",max_file]), shell = True)\n",
    "    sp.check_output(' '.join([\"fslstats -t\",merge_file,\"-P 0 >\",min_file]), shell = True)\n",
    "    thresh_d[fac]={'lower':get_thresh(min_file,2.5),\n",
    "                   'upper':get_thresh(max_file,97.5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event': {'lower': -32582.407373050002, 'upper': 27280.050488149998},\n",
       " 'ham': {'lower': -31994.015869374998, 'upper': 28533.615820674993}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cj = ('ham','ham-viv_ave')\n",
    "fac = cj[0]+'_cj_'+cj[1]\n",
    "for n in range(1000):\n",
    "    cjin1 = os.path.join(outdir,'stats',stat_out_pat%(cj[0],m,run_name,run_type,n))\n",
    "    cjin2 = os.path.join(outdir,'stats',stat_out_pat%(cj[1],m,run_name,run_type,n))\n",
    "    cj1_post_file = os.path.join(outdir,'stats',pp_out_pat%(cj[0],m,run_name,run_type,'pos_t',n))\n",
    "    cj2_negt_file = os.path.join(outdir,'stats',pp_out_pat%(cj[1],m,run_name,run_type,'neg_t',n))\n",
    "    cj_t = os.path.join(outdir,'stats',pp_out_pat%(fac,m,run_name,run_type,'t',n))\n",
    "    cj_tfce = os.path.join(outdir,'stats',pp_out_pat%(fac,m,run_name,run_type,'cj_tfce',n))\n",
    "\n",
    "    sp.check_output(' '.join(['fslmaths',cjin1,'-thr 0',cj1_post_file]), shell = True)\n",
    "    sp.check_output(' '.join(['fslmaths',cjin2,'-mul -1 -thr 0',cj2_negt_file]), shell = True)\n",
    "    sp.check_output(' '.join(['fslmaths',cj1_post_file,'-min',cj2_negt_file,cj_t]), shell = True)\n",
    "    sp.check_output(' '.join(['fslmaths',cj_t,'-thr 0 -tfce 2 0.6666 26',cj_tfce]), shell = True)\n",
    "\n",
    "    #sp.check_output(' '.join(['rm', cj1_tfce_pos_file]), shell = True)\n",
    "    #sp.check_output(' '.join(['rm', cj2_tfce_neg_file]), shell = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fac = cj[0]+'_cj_'+cj[1]\n",
    "merge_input = os.path.join(outdir,'stats',merge_in_pat%(fac,m,run_name,run_type,'cj_tfce'))\n",
    "merge_file = os.path.join(outdir,'stats',merge_out_pat%(fac,m,run_name,run_type,'tfce_merge'))\n",
    "max_file = os.path.join(outdir,'stats',merge_out_pat%(fac,m,run_name,run_type,'tfce_max_vals'))\n",
    "min_file = os.path.join(outdir,'stats',merge_out_pat%(fac,m,run_name,run_type,'tfce_min_vals'))\n",
    "\n",
    "sp.check_output(' '.join([\"fslmerge -t\",merge_file,merge_input]),shell = True)\n",
    "sp.check_output(' '.join([\"fslstats -t\",merge_file,\"-a -P 100 >\",max_file]), shell = True)\n",
    "sp.check_output(' '.join([\"fslstats -t\",merge_file,\"-a -P 0 >\",min_file]), shell = True)\n",
    "thresh_d[fac]={'upper_1sided':get_thresh(max_file,95)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "for fac in contrasts.keys():\n",
    "    tfce_file = os.path.join(outdir,'stats',pp_out_pat%(fac,m,run_name,run_type,'tfce',n))\n",
    "    thresh_d[fac]['min'] = float(sp.check_output(' '.join(['fslstats',tfce_file,'-P 0']), shell = True).strip())\n",
    "    thresh_d[fac]['max'] = float(sp.check_output(' '.join(['fslstats',tfce_file,'-P 100']), shell = True).strip())\n",
    "\n",
    "#cjs = ('ham','ham-viv_ave')\n",
    "#fac = cj[0]+'_cj_'+cj[1]\n",
    "#cj_tfce = os.path.join(outdir,'stats',pp_out_pat%(fac,m,run_name,run_type,'cj_tfce',n))\n",
    "#thresh_d[fac]['min'] = float(sp.check_output(' '.join(['fslstats',cj_tfce,'-P 0']), shell = True).strip())\n",
    "#thresh_d[fac]['max'] = float(sp.check_output(' '.join(['fslstats',cj_tfce,'-P 100']), shell = True).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh_out = os.path.join(outdir,'stats',\"%s.tfce_thresholds.csv\"%run_name)\n",
    "pd.DataFrame(thresh_d).to_csv(thresh_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lower</th>\n",
       "      <td>-3.258241e+04</td>\n",
       "      <td>-31994.015869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.238561e+06</td>\n",
       "      <td>44151.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.705415e+03</td>\n",
       "      <td>-1935.239136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper</th>\n",
       "      <td>2.728005e+04</td>\n",
       "      <td>28533.615821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              event           ham\n",
       "lower -3.258241e+04 -31994.015869\n",
       "max    1.238561e+06  44151.562500\n",
       "min    4.705415e+03  -1935.239136\n",
       "upper  2.728005e+04  28533.615821"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(thresh_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
